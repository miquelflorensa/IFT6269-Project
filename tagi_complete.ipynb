{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tractable Gaussian Approximate Infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAGI:\n",
    "    \"\"\"\n",
    "    Implementation of TAGI (Traceable Approximate Gaussian Inference) based on the paper:\n",
    "    Tractable approximate Gaussian inference for Bayesian neural networks (James-A. Goulet, Luong-Ha Nguyen, and Said Amiri. JMLR, 2021)\n",
    "    https://jmlr.csail.mit.edu/papers/volume22/20-1009/20-1009.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        \"\"\"\n",
    "        Initialize the TAGI model.\n",
    "\n",
    "        Input:\n",
    "        layers: list of integers, specifying the number of neurons in each layer.\n",
    "\n",
    "        Output:\n",
    "        Initializes the model parameters and hidden states.\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.parameters = self.init_parameters(layers)\n",
    "        self.hidden_states = self.init_hidden_states(layers)\n",
    "        self.covariances = self.init_covariances(layers)\n",
    "        self.mu = 0\n",
    "        self.sigma = 1\n",
    "\n",
    "    def standardize_data(self, X):\n",
    "        \"\"\"\n",
    "        Standardize the input data by subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "        Input:\n",
    "        X: ndarray of shape (n_samples), the input data.\n",
    "\n",
    "        Output:\n",
    "        ndarray of shape (n_samples), the standardized data.\n",
    "        \"\"\"\n",
    "        self.mu = np.mean(X)\n",
    "        self.sigma = np.std(X)\n",
    "        return (X - self.mu) / self.sigma\n",
    "\n",
    "    def unstandardize_data(self, X):\n",
    "        \"\"\"\n",
    "        Convert standardized data back to its original scale.\n",
    "\n",
    "        Input:\n",
    "        X: ndarray of shape (n_samples), the standardized data.\n",
    "\n",
    "        Output:\n",
    "        ndarray of shape (n_samples), the unstandardized data.\n",
    "        \"\"\"\n",
    "        return X * self.sigma + self.mu\n",
    "\n",
    "    def init_parameters(self, layers):\n",
    "        \"\"\"\n",
    "        Initialize weights and biases for each layer.\n",
    "\n",
    "        Input:\n",
    "        layers: list of integers, specifying the number of neurons in each layer.\n",
    "\n",
    "        Output:\n",
    "        parameters: list of dictionaries, where each dictionary contains:\n",
    "            - mw: ndarray of shape (n_inputs, n_outputs), the mean values of the weights.\n",
    "            - Sw: ndarray of shape (n_inputs, n_outputs), the variances of the weights.\n",
    "            - mb: ndarray of shape (n_outputs,), the mean values of the biases.\n",
    "            - Sb: ndarray of shape (n_outputs,), the variances of the biases.\n",
    "        \"\"\"\n",
    "        parameters = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            input_size = layers[i]\n",
    "            output_size = layers[i + 1]\n",
    "            parameters.append(\n",
    "                {\n",
    "                    \"mw\": np.random.randn(output_size, input_size)\n",
    "                    * (0.5 / input_size) ** 0.5,\n",
    "                    \"Sw\": np.ones((output_size, input_size)) / input_size,\n",
    "                    \"mb\": np.random.randn(output_size, 1) * 1 / input_size,\n",
    "                    \"Sb\": np.ones((output_size, 1)) * 0.5,\n",
    "                }\n",
    "            )\n",
    "        return parameters\n",
    "\n",
    "    def init_hidden_states(self, layers):\n",
    "        \"\"\"\n",
    "        Initialize the hidden states for each layer.\n",
    "\n",
    "        Input:\n",
    "        layers: list of integers, specifying the number of neurons in each layer.\n",
    "\n",
    "        Output:\n",
    "        hidden_states: list of dictionaries, where each dictionary contains:\n",
    "            - 'ma': ndarray of shape (n_neurons,1), the mean values of the activation units.\n",
    "            - 'Sa': ndarray of shape (n_neurons,n_neurons), the variances of the activation units.\n",
    "            - 'J': ndarray of shape (n_neurons,1), the Jacobian of the activation function.\n",
    "        \"\"\"\n",
    "        hidden_states = []\n",
    "        for layer_size in layers:\n",
    "            hidden_states.append(\n",
    "                {\n",
    "                    \"ma\": np.zeros((layer_size, 1)),\n",
    "                    \"Sa\": np.ones((layer_size, 1)),\n",
    "                    \"J\": np.ones((layer_size, 1)),\n",
    "                }\n",
    "            )\n",
    "        return hidden_states\n",
    "\n",
    "    def init_covariances(self, layers):\n",
    "        \"\"\"\n",
    "        Initialize the covariances for each layer.\n",
    "\n",
    "        Input:\n",
    "        layers: list of integers, specifying the number of neurons in each layer.\n",
    "\n",
    "        Output:\n",
    "        covariances: list of dictionaries, where each dictionary contains:\n",
    "            - 'covZw': ndarray of shape (n_inputs, n_outputs), the covariances of the hidden states and weights.\n",
    "            - 'covZb': ndarray of shape (n_outputs,), the covariances of the hidden states and biases.\n",
    "            - 'covZZ': ndarray of shape (n_neurons, n_neurons), the covariances of two consecutive hidden states.\n",
    "        \"\"\"\n",
    "        covariances = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            input_size = layers[i]\n",
    "            output_size = layers[i + 1]\n",
    "            covariances.append(\n",
    "                {\n",
    "                    \"covZw\": np.zeros((output_size, input_size)),\n",
    "                    \"covZb\": np.zeros((output_size, 1)),\n",
    "                    \"covZZ\": np.zeros((output_size, input_size)),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return covariances\n",
    "\n",
    "    def GMA(self, ma, Sa, mw, Sw):\n",
    "        \"\"\"\n",
    "        Gaussian Multiplicative Approximation (GMA)\n",
    "\n",
    "        Input:\n",
    "        ma: ndarray of shape (n_inputs,), mean values of the activation units.\n",
    "        Sa: ndarray of shape (n_inputs,), variances of the activation units.\n",
    "        mw: ndarray of shape (n_inputs, n_outputs), mean values of the weights.\n",
    "        Sw: ndarray of shape (n_inputs, n_outputs), variances of the weights.\n",
    "\n",
    "        Output:\n",
    "        mu: ndarray of shape (n_outputs,), the means of the next hidden layer.\n",
    "        var: ndarray of shape (n_outputs,), the variances of the next hidden layer.\n",
    "\n",
    "        Remember that in GMA, given X1 and X2 random gaussian variables,\n",
    "        Expected value: E[X1 * X2] = μ1 * μ2 + cov(X1, X2)\n",
    "        Variance: var[X1 * X2] = var(X1) * var(X2) + cov(X1, X2)^2 +\n",
    "                  2cov(X1,X2)μ1μ2 + var(X1) * μ2^2 + var(X2) * μ1^2\n",
    "\n",
    "        Also remebmer that the activation units and the weights are independent in a neural network.\n",
    "        \"\"\"\n",
    "        # To-do: Implement GMA and compute mu and var.\n",
    "\n",
    "        # Expected value E[X1 * X2] = μ1 * μ2\n",
    "        mu = mw @ ma  # Matrix product of means\n",
    "\n",
    "        # Variance calculation\n",
    "        # var[X1 * X2] = Sa * Sw + (Sa * mw^2) + (Sw * ma^2)\n",
    "        var = (Sw @ Sa) + (Sw @ ma**2) + (mw**2 @ Sa)\n",
    "\n",
    "        mu = mu.reshape(-1, 1)\n",
    "        var = var.reshape(-1, 1)\n",
    "\n",
    "        return mu, var\n",
    "\n",
    "    def ReLU(self, mz, Sz):\n",
    "        \"\"\"\n",
    "        Rectified Linear Unit (ReLU) activation function.\n",
    "\n",
    "        Input:\n",
    "        mz: ndarray of shape (n_samples,), the hidden states.\n",
    "        Sz: ndarray of shape (n_samples,), the variances of the hidden states.\n",
    "\n",
    "        Output:\n",
    "        ndarray of shape (n_samples,), the output values.\n",
    "        \"\"\"\n",
    "\n",
    "        # To-do: Implement ReLU activation function and compute ma, Sa and J\n",
    "        ma = np.maximum(0, mz)\n",
    "        Sa = Sz * (mz > 0)\n",
    "        J = (mz > 0).astype(int)\n",
    "\n",
    "        return ma, Sa, J\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the network using GMA.\n",
    "\n",
    "        Input:\n",
    "        X: ndarray of shape (n_inputs,), the input data.\n",
    "\n",
    "        Output:\n",
    "        Y: ndarray of shape (n_outputs,), the output values.\n",
    "\n",
    "        It is suggested to compute the coariances at the same time you perform the forward pass.\n",
    "        \"\"\"\n",
    "\n",
    "        # To-do: Implement forward pass using GMA and compute the covariances.\n",
    "        self.hidden_states[0][\"ma\"], self.hidden_states[0][\"Sa\"] = X, np.zeros_like(X)\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            ma, Sa = self.hidden_states[i][\"ma\"], self.hidden_states[i][\"Sa\"]\n",
    "            mw, Sw = self.parameters[i][\"mw\"], self.parameters[i][\"Sw\"]\n",
    "            mb, Sb = self.parameters[i][\"mb\"], self.parameters[i][\"Sb\"]\n",
    "\n",
    "            # Apply GMA\n",
    "            print(ma.shape, Sa.shape, mw.shape, Sw.shape)\n",
    "            mz, Sz = self.GMA(ma, Sa, mw, Sw)\n",
    "            mz = mz + mb\n",
    "            Sz = Sz + Sb\n",
    "\n",
    "            # Apply ReLU if not the output layer\n",
    "            J = np.ones_like(mz)\n",
    "            if i < len(self.layers) - 2:\n",
    "                ma, Sa, J = self.ReLU(mz, Sz)\n",
    "            else:\n",
    "                ma, Sa = mz, Sz\n",
    "\n",
    "            # print(ma.shape, Sa.shape, J.shape)\n",
    "\n",
    "            self.hidden_states[i + 1] = {\"ma\": ma, \"Sa\": Sa, \"J\": J}\n",
    "\n",
    "            # Update covariances at the same time\n",
    "            self.covariances[i][\"covZw\"] = Sw.T @ ma\n",
    "            self.covariances[i][\"covZb\"] = Sb\n",
    "            # print(Sz.shape, J.shape, mw.shape)\n",
    "            self.covariances[i][\"covZZ\"] = Sz @ J.T @ mw\n",
    "\n",
    "        # Output layer\n",
    "        return self.hidden_states[-1][\"ma\"]\n",
    "\n",
    "    def backward(self, Y, sigma_v):\n",
    "        \"\"\"\n",
    "        Perform a backward pass through the network using Bayesian inference.\n",
    "\n",
    "        Input:\n",
    "        Y: ndarray of shape (n_outputs,), the output values.\n",
    "        sigma_v: float, the observation noise.\n",
    "\n",
    "        We are just gonna update the parameters and not the hidden states.\n",
    "\n",
    "        Infer posterior mean and diagonal covariance for the output layer:\n",
    "        - f(z_out|y) = N(z_out; mu_{z_out|y}, Sigma_{z_out|y})\n",
    "        - mu_{z_out|y} = mu_{z_out} + cov_{Y, Z_out}^T * cov_{Y}^{-1} * (y - mu_Y)\n",
    "        - Sigma_{z_out|y} = Sigma_{z_out} - cov_{Y, Z_out}^T * cov_{Y}^{-1} * cov_{Y, Z_out}\n",
    "\n",
    "        RTS smoother for the parameters:\n",
    "        - f(\\theta|y) = N(\\theta; mu_{\\theta|y}, Sigma_{\\theta|y})\n",
    "        - mu_{\\theta|y} = mu_{\\theta} + J_{\\theta} * (mu_{Z+|y} - mu_{Z+})\n",
    "        - Sigma_{\\theta|y} = Sigma_{\\theta} + J_{\\theta} * (Sigma_{Z+|y} - Sigma_{Z+}) * J_{\\theta}^T\n",
    "\n",
    "            where:\n",
    "            - J_{\\theta} = cov_{\\theta, Z+} * cov_{Z+}^{-1}\n",
    "        \"\"\"\n",
    "\n",
    "        # Update output layer\n",
    "        mu_y = self.hidden_states[-1][\"ma\"]  # Predicted mean of the output\n",
    "        Sigma_y = (\n",
    "            self.hidden_states[-1][\"Sa\"] + sigma_v**2\n",
    "        )  # Total variance of the output (add noise)\n",
    "        cov_yZ = (\n",
    "            self.hidden_states[-1][\"Sa\"] / Sigma_y\n",
    "        )  # Covariance between output and last hidden state\n",
    "\n",
    "        # Infer posterior for the output layer\n",
    "        residual = Y - mu_y  # Error between predicted and true output\n",
    "        mu_z_out_y = mu_y + cov_yZ * residual  # Posterior mean of the last hidden state\n",
    "        Sigma_z_out_y = (\n",
    "            self.hidden_states[-1][\"Sa\"] - cov_yZ**2 * Sigma_y\n",
    "        )  # Posterior variance of the last hidden state\n",
    "\n",
    "        # Update the output layer's hidden state parameters\n",
    "        self.hidden_states[-1][\"ma\"] = mu_z_out_y\n",
    "        self.hidden_states[-1][\"Sa\"] = Sigma_z_out_y\n",
    "\n",
    "        # RTS smoother for parameters\n",
    "        for i in reversed(range(len(self.layers) - 1)):\n",
    "            # Retrieve forward pass values\n",
    "            J_theta = self.covariances[i][\"covZw\"] / (\n",
    "                self.hidden_states[i + 1][\"Sa\"] + 1e-8\n",
    "            )  # Avoid division by zero\n",
    "            mu_theta = self.parameters[i][\"mw\"]  # Mean of the parameters (weights)\n",
    "            Sigma_theta = self.parameters[i][\n",
    "                \"Sw\"\n",
    "            ]  # Variance of the parameters (weights)\n",
    "\n",
    "            # Retrieve posterior values from next layer\n",
    "            mu_z_next_y = self.hidden_states[i + 1][\"ma\"]\n",
    "            Sigma_z_next_y = self.hidden_states[i + 1][\"Sa\"]\n",
    "\n",
    "            # Update posterior for the current layer's parameters\n",
    "            delta_mu_z = mu_z_next_y - self.hidden_states[i + 1][\"ma\"]\n",
    "            delta_Sigma_z = Sigma_z_next_y - self.hidden_states[i + 1][\"Sa\"]\n",
    "\n",
    "            # Compute updated mean and variance for parameters\n",
    "            mu_theta_y = mu_theta + J_theta * delta_mu_z\n",
    "            Sigma_theta_y = Sigma_theta + J_theta * delta_Sigma_z * J_theta.T\n",
    "\n",
    "            # Save updated parameter posterior\n",
    "            self.parameters[i][\"mw\"] = mu_theta_y\n",
    "            self.parameters[i][\"Sw\"] = Sigma_theta_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13e5a1250>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate data\n",
    "X = np.linspace(0, 10, 100).reshape(-1, 1)  # Ensure X is 2D\n",
    "Y = (np.sin(X).flatten() + np.random.normal(0, 0.1, 100)) * 10\n",
    "\n",
    "# Shuffle data\n",
    "indices = np.arange(100)\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "Y = Y[indices].reshape(-1, 1)\n",
    "\n",
    "# Split data\n",
    "train_X, test_X = X[:80], X[80:]\n",
    "train_Y, test_Y = Y[:80], Y[80:]\n",
    "\n",
    "# Plot the training data\n",
    "plt.scatter(train_X, train_Y, marker=\"o\", color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1) (50, 1) (50, 1) (50, 1)\n",
      "(1, 1) (1, 1) (1, 1)\n",
      "(50, 1) (50, 1) (50, 1)\n",
      "-------------------\n",
      "(1, 50) (1, 50) (1, 1) (1, 1)\n",
      "(50, 1) (50, 1) (50, 1)\n",
      "(1, 50) (1, 1) (1, 50)\n",
      "-------------------\n",
      "(1,) (1,) (50, 1) (50, 1)\n",
      "(50, 1) (50, 1) (1, 50) (1, 50)\n",
      "(1,) (1,) (50, 1) (50, 50)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(train_X, train_Y):\n\u001b[0;32m---> 32\u001b[0m         \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m         net\u001b[38;5;241m.\u001b[39mbackward(y, \u001b[38;5;241m0.01\u001b[39m)\n",
      "Cell \u001b[0;32mIn[93], line 208\u001b[0m, in \u001b[0;36mTAGI.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Apply GMA\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mprint\u001b[39m(ma\u001b[38;5;241m.\u001b[39mshape, Sa\u001b[38;5;241m.\u001b[39mshape, mw\u001b[38;5;241m.\u001b[39mshape, Sw\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 208\u001b[0m mz, Sz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGMA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m mz \u001b[38;5;241m=\u001b[39m mz \u001b[38;5;241m+\u001b[39m mb\n\u001b[1;32m    210\u001b[0m Sz \u001b[38;5;241m=\u001b[39m Sz \u001b[38;5;241m+\u001b[39m Sb\n",
      "Cell \u001b[0;32mIn[93], line 159\u001b[0m, in \u001b[0;36mTAGI.GMA\u001b[0;34m(self, ma, Sa, mw, Sw)\u001b[0m\n\u001b[1;32m    155\u001b[0m mu \u001b[38;5;241m=\u001b[39m mw \u001b[38;5;241m@\u001b[39m ma  \u001b[38;5;66;03m# Matrix product of means\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Variance calculation\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# var[X1 * X2] = Sa * Sw + (Sa * mw^2) + (Sw * ma^2)\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m var \u001b[38;5;241m=\u001b[39m (\u001b[43mSw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSa\u001b[49m) \u001b[38;5;241m+\u001b[39m (Sw \u001b[38;5;241m@\u001b[39m ma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m (mw\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m@\u001b[39m Sa)\n\u001b[1;32m    161\u001b[0m mu \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    162\u001b[0m var \u001b[38;5;241m=\u001b[39m var\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 50)"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "net = TAGI([1, 50, 1])\n",
    "train_X = net.standardize_data(train_X)\n",
    "train_Y = net.standardize_data(train_Y)\n",
    "\n",
    "\n",
    "for i in range(len(net.layers) - 1):\n",
    "    print(\n",
    "        net.parameters[i][\"mw\"].shape,\n",
    "        net.parameters[i][\"Sw\"].shape,\n",
    "        net.parameters[i][\"mb\"].shape,\n",
    "        net.parameters[i][\"Sb\"].shape,\n",
    "    )\n",
    "    print(\n",
    "        net.hidden_states[i][\"ma\"].shape,\n",
    "        net.hidden_states[i][\"Sa\"].shape,\n",
    "        net.hidden_states[i][\"J\"].shape,\n",
    "    )\n",
    "    print(\n",
    "        net.covariances[i][\"covZw\"].shape,\n",
    "        net.covariances[i][\"covZb\"].shape,\n",
    "        net.covariances[i][\"covZZ\"].shape,\n",
    "    )\n",
    "    print(\"-------------------\")\n",
    "\n",
    "# net.forward(train_X[0])\n",
    "# net.backward(train_Y[1], 0.01)\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for x, y in zip(train_X, train_Y):\n",
    "        net.forward(x)\n",
    "        net.backward(y, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009\n",
      " -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009\n",
      " -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009\n",
      " -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009\n",
      " -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009\n",
      " -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009\n",
      " -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009\n",
      " -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009 -1.45961009\n",
      " -1.45961009 -1.45961009]\n",
      "[-1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364\n",
      " -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364\n",
      " -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364\n",
      " -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364\n",
      " -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364\n",
      " -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364\n",
      " -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364\n",
      " -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364 -1.86225364\n",
      " -1.86225364 -1.86225364]\n",
      "[-1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807\n",
      " -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807\n",
      " -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807\n",
      " -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807\n",
      " -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807\n",
      " -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807\n",
      " -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807\n",
      " -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807 -1.0583807\n",
      " -1.0583807 -1.0583807]\n",
      "[-0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158\n",
      " -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158\n",
      " -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158\n",
      " -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158\n",
      " -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158\n",
      " -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158\n",
      " -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158\n",
      " -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158 -0.09504158\n",
      " -0.09504158 -0.09504158]\n",
      "[-0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471\n",
      " -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471\n",
      " -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471\n",
      " -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471\n",
      " -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471\n",
      " -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471\n",
      " -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471\n",
      " -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471 -0.95145471\n",
      " -0.95145471 -0.95145471]\n",
      "[-0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674\n",
      " -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674\n",
      " -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674\n",
      " -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674\n",
      " -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674\n",
      " -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674\n",
      " -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674\n",
      " -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674 -0.36413674\n",
      " -0.36413674 -0.36413674]\n",
      "[-1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066\n",
      " -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066\n",
      " -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066\n",
      " -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066\n",
      " -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066\n",
      " -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066\n",
      " -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066\n",
      " -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066 -1.8478066\n",
      " -1.8478066 -1.8478066]\n",
      "[-1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062\n",
      " -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062\n",
      " -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062\n",
      " -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062\n",
      " -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062\n",
      " -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062\n",
      " -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062\n",
      " -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062 -1.23020062\n",
      " -1.23020062 -1.23020062]\n",
      "[-0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754\n",
      " -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754\n",
      " -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754\n",
      " -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754\n",
      " -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754\n",
      " -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754\n",
      " -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754\n",
      " -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754 -0.98749754\n",
      " -0.98749754 -0.98749754]\n",
      "[-0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382\n",
      " -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382\n",
      " -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382\n",
      " -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382\n",
      " -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382\n",
      " -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382\n",
      " -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382\n",
      " -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382 -0.53347382\n",
      " -0.53347382 -0.53347382]\n",
      "[-1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194\n",
      " -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194\n",
      " -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194\n",
      " -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194\n",
      " -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194\n",
      " -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194\n",
      " -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194\n",
      " -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194 -1.00523194\n",
      " -1.00523194 -1.00523194]\n",
      "[-1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215\n",
      " -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215\n",
      " -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215\n",
      " -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215\n",
      " -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215\n",
      " -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215\n",
      " -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215\n",
      " -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215 -1.67444215\n",
      " -1.67444215 -1.67444215]\n",
      "[-0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439\n",
      " -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439\n",
      " -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439\n",
      " -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439\n",
      " -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439\n",
      " -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439\n",
      " -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439\n",
      " -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439 -0.68129439\n",
      " -0.68129439 -0.68129439]\n",
      "[-1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438\n",
      " -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438\n",
      " -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438\n",
      " -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438\n",
      " -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438\n",
      " -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438\n",
      " -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438\n",
      " -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438 -1.26549438\n",
      " -1.26549438 -1.26549438]\n",
      "[-1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032\n",
      " -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032\n",
      " -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032\n",
      " -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032\n",
      " -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032\n",
      " -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032\n",
      " -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032\n",
      " -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032 -1.53235032\n",
      " -1.53235032 -1.53235032]\n",
      "[-0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538\n",
      " -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538\n",
      " -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538\n",
      " -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538\n",
      " -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538\n",
      " -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538\n",
      " -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538\n",
      " -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538 -0.40798538\n",
      " -0.40798538 -0.40798538]\n",
      "[-0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267\n",
      " -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267\n",
      " -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267\n",
      " -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267\n",
      " -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267\n",
      " -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267\n",
      " -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267\n",
      " -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267 -0.81979267\n",
      " -0.81979267 -0.81979267]\n",
      "[-1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438\n",
      " -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438\n",
      " -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438\n",
      " -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438\n",
      " -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438\n",
      " -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438\n",
      " -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438\n",
      " -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438 -1.76112438\n",
      " -1.76112438 -1.76112438]\n",
      "[-1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559\n",
      " -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559\n",
      " -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559\n",
      " -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559\n",
      " -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559\n",
      " -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559\n",
      " -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559\n",
      " -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559 -1.51402559\n",
      " -1.51402559 -1.51402559]\n",
      "[-0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631\n",
      " -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631\n",
      " -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631\n",
      " -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631\n",
      " -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631\n",
      " -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631\n",
      " -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631\n",
      " -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631 -0.83961631\n",
      " -0.83961631 -0.83961631]\n",
      "[[  5.12036633]\n",
      " [  1.52294486]\n",
      " [-10.15282335]\n",
      " [  1.40854141]\n",
      " [ -6.80492819]\n",
      " [ 10.41619552]\n",
      " [  3.53004582]\n",
      " [ -7.39830981]\n",
      " [ -8.87442799]\n",
      " [ 10.00862719]\n",
      " [ -9.83376315]\n",
      " [  9.97712093]\n",
      " [  8.84365709]\n",
      " [ -5.7975826 ]\n",
      " [  7.89045139]\n",
      " [  9.79155124]\n",
      " [  0.48095593]\n",
      " [  9.33510326]\n",
      " [  7.81515854]\n",
      " [ -1.79384722]]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "test_Y_pred = []\n",
    "for x in test_X:\n",
    "    prediction = net.forward(x)\n",
    "    test_Y_pred.append(prediction[0])\n",
    "    print(prediction)\n",
    "test_Y_pred = np.array(test_Y_pred).flatten()\n",
    "test_Y_pred = net.unstandardize_data(test_Y_pred)\n",
    "\n",
    "print(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10782c6d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGdCAYAAADT1TPdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAs3ElEQVR4nO3df3RUZX7H8c8wQAJIxpUfIWEGEn/0iGKVHz0U3GjobrHWUugYV8FaOKu2trImoitaXAVXTLXVhq5CgV1ht3tAWpjdrj3urqwFjWVZWJbYXaGLKyAxJA14bAZYCTA8/eM6MZNMJjPJzNw7c9+vc+bkzJ2b5CtjZj7z3Of5Ph5jjBEAAIBDDbC7AAAAgEQIKwAAwNEIKwAAwNEIKwAAwNEIKwAAwNEIKwAAwNEIKwAAwNEIKwAAwNEG2l1Af124cEHHjh3T8OHD5fF47C4HAAAkwRijkydPqrS0VAMGJB47yfmwcuzYMQUCAbvLAAAAfdDY2Ci/35/wnJwPK8OHD5dk/ccWFRXZXA0AAEhGOBxWIBDoeB9PJOfDSvTST1FREWEFAIAck8wUDibYAgAARyOsAAAARyOsAAAARyOsAAAARyOsAAAARyOsAAAARyOsAAAARyOsAAAAR8v5pnDoWSQi1ddLzc1SSYlUUSF5vXZXBQBAaggreSoUkqqrpQ8//OyY3y+tXCkFg/bVBQBAqrgMlIdCIamqKjaoSFJTk3U8FLKnLgAA+oKwkmciEWtExZjuj0WP1dRY5wEAkAsIK3mmvr77iEpnxkiNjdZ5AADkAsJKnmluTu95AADYjbCSZ0pK0nseAAB2YzVQnqmosFb9NDXFn7fi8ViPV1Rkty6WUQPINbxuOUdGR1beeustzZ49W6WlpfJ4PPr+978f87gxRsuWLVNpaamGDBmiyspKvfvuu5ksKe95vdbyZMkKJp1F79fVZfcPLhSSysqkmTOl+fOtr2VlrEoC4Fy8bjlLRsPK6dOnde211+rFF1+M+/hzzz2nF154QS+++KL27NmjMWPG6A//8A918uTJTJaV94JBacsWaezY2ON+v3U8m31WWEYNINfwuuU8HmPiXSzIwC/yePS9731Pc+fOlWSNqpSWlqqmpkZLliyRJLW3t6u4uFjPPvus/uqv/iqpnxsOh+Xz+dTW1qaioqJMlZ+Tkh3CzNRQZyRifRLpaXVS9JLU4cMMrQJwBl63sieV92/bJtgePnxYLS0tmjVrVsexgoIC3Xjjjdq5c2eP39fe3q5wOBxzQ3xer1RZKc2bZ32N94eVyaFOllEDyDW8bjmTbWGlpaVFklRcXBxzvLi4uOOxeGpra+Xz+TpugUAgo3Xms0wPdbKMGkCu4XXLmWxfuuzpMgvUGNPtWGePPfaY2traOm6NjY2ZLjEvZaPTLcuoAeQaXrecybawMmbMGEnqNorS2trabbSls4KCAhUVFcXckLpsDHVGl1H3lD09HikQyP4yagDoCa9bzmRbWCkvL9eYMWO0bdu2jmNnz57Vm2++qRkzZthVlmtkY6jTicuoASARXrecKaNh5dSpU2poaFBDQ4Mka1JtQ0ODjh49Ko/Ho5qaGj3zzDP63ve+p1/96ldauHChhg4dqvnz52eyLCh7Q51OWkYNAMngdct5Mrp0eceOHZo5c2a34wsWLNCGDRtkjNHy5cu1Zs0affzxx5o2bZpeeuklTZw4MenfwdLlvokuz+ut0226lufRCRJAruF1K7NSef/OWp+VTCGs9F10NZAUG1iiQ518ggCA7HNLSMqJPiuwH0OdAOAstPmPj5EVuCbFA4CTRUe7u74r5+toN5eBAADIIW5s889lIAAAcght/hMjrAAAYDPa/CdGWAEAwGa0+U+MsAIAgM1o858YYQV5LRKRduyQNm2yvvZnY0YAyBTa/CdGWEHeol8BgFxC76uesXQZeclt/QoA5A+39L6izwpczY39CgAg19BnBa5GvwIAyC+EFeQd+hUAQH4hrCDv0K8AAPILYQV5h34FAJBfCCvIO/QrAID8QlhBXqJfAQDkj4F2FwBkSjAozZnjjn4FAJDPCCvIa16vVFlpdxUAgP7gMhAAAHA0wgoAAHA0wgoAAHA05qwAAGzhlg370H+EFQBAVnQOJ++9J61dKzU1ffa432/1SKK1ALoirAAAMi4UkqqrE28y2tQkVVXRCwndMWcFAJBRoZAVQhIFFcnaEV2SamqsURggirACAMiYSMQaUYkGkd4YIzU2WpeLgCjCCgAgY+rrex9Riae5Of21IHcRVgAAGdPX0FFSkt46kNuYYAsAyJhUQ4fHY60KqqjITD3ITYysAAAypqLCCh8eT+/nRs+pq6PfCmIRVgAAGeP1Wr1TpN4Di9/PsmXEx2UgAEBGBYNWCOnaZ8Xvl+69V7riCjrYIjHCCgAg44JBac4c2uujbwgrAICs8Hqlykq7q0AuYs4KAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwNMIKAABwtIF2FwAAyB2RiFRfLzU3SyUlUkWF5PXaXRXyHWEFAJCUUEiqrpY+/PCzY36/tHKlFAzaVxfyH5eBAAC9CoWkqqrYoCJJTU3W8VDInrrgDraHlWXLlsnj8cTcxowZY3dZAIBPRSLWiIox3R+LHqupsc4DMsERl4Guvvpq/eQnP+m47+UCKAA4Rn199xGVzoyRGhut8yors1YWXMQRYWXgwIGMpgCAQzU3p/c8IFW2XwaSpPfee0+lpaUqLy/XHXfcoUOHDvV4bnt7u8LhcMwNAJA5JSXpPQ9Ile1hZdq0afrOd76jH//4x1q3bp1aWlo0Y8YMffTRR3HPr62tlc/n67gFAoEsVwwA7lJRYa368XjiP+7xSIGAdR6QCR5j4k2Zss/p06d12WWX6ZFHHtHixYu7Pd7e3q729vaO++FwWIFAQG1tbSoqKspmqQDgGtHVQFLsRNtogNmyheXLSE04HJbP50vq/dv2kZWuhg0bpmuuuUbvvfde3McLCgpUVFQUcwMAZFYwaAWSsWNjj/v9BBVkniMm2HbW3t6uAwcOqILxRABwlGBQmjOHDrbIPtvDysMPP6zZs2dr3Lhxam1t1dNPP61wOKwFCxbYXRoAoAuvl+XJyD7bw8qHH36oefPm6cSJExo1apR+//d/X7t27dL48ePtLg0AADiA7WHllVdesbsEAADgYI6bYAsAANAZYQUAADgaYQUAADgaYQUAADgaYQUAADgaYQUAADgaYQUAADgaYQUAADgaYQUAADgaYQUAADgaYQUAADia7XsDAQAA+0UiUn291NwslZRIFRXWLttOQFgBAMDlQiGpulr68MPPjvn90sqVUjBoX11RXAYCAMDFQiGpqio2qEhSU5N1PBSyp67OCCsAALhUJGKNqBjT/bHosZoa6zw7EVYAAHCp+vruIyqdGSM1Nlrn2YmwAgCASzU3p/e8TCGsAADgUiUl6T0vUwgrAAC4VEWFterH44n/uMcjBQLWeXYirAAA4FJer7U8WeoeWKL36+rs77dCWAEAwMWCQWnLFmns2Njjfr913Al9VmgKBwCAywWD0pw5dLAFAAAO5vVKlZV2VxEfl4EAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjEVYAAICjDbS7AAAA4EyRiFRfLzU3SyUlUkWF5PVmvw7CCgAA6CYUkqqrpQ8//OyY3y+tXCkFg9mthctAPYhEpB07pE2brK+RiN0VAQCQHaGQVFUVG1QkqanJOh4KZbcewkocoZBUVibNnCnNn299LSvL/pMDAEC2RSLWiIox3R+LHqupye6HeMJKF05LkwAAZFN9fff3wM6MkRobrfOyhbDSSec0OUAR3agdukObdKN2yGOsCJntNAkAQDY1N6f3vHQgrHQSTZN/ppCOqEw7NFObNF87NFNHVKa5JpT1NAkAQDaVlKT3vHQgrHTS3GwFlS2q0ljFjoGNVZO2qEp/plBW0yQAANlUUWGt+vF44j/u8UiBgHVethBWOikZHdFKVUsy3f5hBsiaVVSnGpWM5joQACA/eb3W8mSpe2CJ3q+ry26/FcJKJxWqV0Af9viPMkBG49SoCnEdCACQv4JBacsWaezY2ON+v3U8231WaArXibc1ues7yZ4HAECuCgalOXPoYOs8TpxVBACATbxeqbLS7iq4DBTLibOKAABwOcJKZ06cVQQAgMsRVrpy2qwiAABcjjkr8ThpVhEAAC5HWOmJU2YVAQDgcoQVIAsiEQbqAKCvCCtAhoVC1gaZnXcx9futudxMgQKA3jHBFsigUEiqquq+3XpTk3U8FLKnLgDIJYQVIEMiEWtExZjuj0WP1dRY5wEAekZYATKkvr77iEpnxkiNjdZ5AICeEVaADGlOcgupZM8DALcirAAZwlZTAJAehBUgQ9hqCgDSwxFhZdWqVSovL1dhYaGmTJmiei7iIw+w1RQApIftYWXz5s2qqanR0qVLtW/fPlVUVOjmm2/W0aNH7S4N6De2mgKA/vMYE29hZfZMmzZNkydP1urVqzuOTZgwQXPnzlVtbW2v3x8Oh+Xz+dTW1qaioqJMlgr0GR1sASBWKu/ftnawPXv2rPbu3atHH3005visWbO0c+dOm6oC0o+tpgCg72wNKydOnFAkElFxcXHM8eLiYrW0tMT9nvb2drW3t3fcD4fDGa0RAADYy/Y5K5Lk6TL70BjT7VhUbW2tfD5fxy0QCGSjRAAAYBNbw8rIkSPl9Xq7jaK0trZ2G22Jeuyxx9TW1tZxa2xszEapAADAJraGlcGDB2vKlCnatm1bzPFt27ZpxowZcb+noKBARUVFMTcAAJC/bJ2zIkmLFy/WXXfdpalTp2r69Olau3atjh49qvvuu8/u0gAAgAPYHlZuv/12ffTRR3rqqafU3NysiRMn6rXXXtP48ePtLi33sV4WAJAHbO+z0l/0WelBKCRVV8du++v3Wy1V6UQGALBZKu/fjlgNhDQLhaSqqtigIklNTdbxUMieugAA6APCSr6JRKwRlXgDZtFjNTXWeQAA5ADCSr6pr+8+otKZMVJjo3VeVCQi7dghbdpkfSXIAAAcxPYJtkiz5ubUzmNuCwDA4RhZyTclJcmfx9wWAEAOIKzkm4oKa2Skh+0K5PFIgYA0YwZzWwAAOYGwkm+8XusSjtQ9sETv19VJO3emPrcFAAAbEFbyUTAobdkijR0be9zvt44Hg6nPbQEAwCZMsM1XwaA0Z07PHWxTmdsCAICNCCv5zOuVKivjPxad29LUFH/eisdjPV5RkdESAQDoDZeB3CrZuS3sJQQAsBlhxc2SmdsCAIDNuAzkdr3NbQEAwGaEFSSe2wIAgM24DAQAAByNsAIAAByNy0DIjkiEeTEAgD4hrCDz2Nk5LvIbACSHy0DILHZ2jisUksrKpJkzpfnzra9lZa795wCAhAgryJxIhJ2d4yC/AUBqCCvInPp6dnbugvwGAKkjrCBz2Nm5G/IbAKSOsILMYWfnbshvAJA6wgoyJ7qzc9eNEqM8HikQcNXOzuQ3AEgdYQWZw87O3ZDfACB1hBVkFjs7xyC/AUDqPMbEW5eQO8LhsHw+n9ra2lRUVGR3OegJHdBixOuTFwhYQcVl+Q2AS6Xy/k1YAWxCfgPgZqm8f9NuH7CJ1ytVVtpdBQA4H3NWAACAoxFWAACAoxFWAACAozFnBfmNWawAkPMIK8hf8dYH+/1WoxPWBwNAzuAyEPJTKCRVVXXfNbCpyToeCtlTFwAgZYQV5J9IxBpRiddCKHqspsY6DwDgeIQV5J/6+u4jKp0ZIzU2WucBAByPsIL809yc3vMAALYirCD/lJSk9zwAgK0IK8g/FRXWqp+u2xpHeTzWroEVFdmtCwDQJ4QV5B+v11qeLHUPLNH7dXX0WwGAHEFYQX4KBqUtW6SxY2OP+/3WcfqsAEDOoCkc8lcwKM2ZQwdbAMhxhBXkN69Xqqy0uwoAQD9wGQgAADgaYQUAADgaYQUAADgac1aAbIhEmOgLAH1EWAEyLRSyNlbsvF+R32/1gmEJNQD0irACZFIoJFVVdd8BuqlJuvVWafly6YorGG0BgAQ8xnR9Fc0t4XBYPp9PbW1tKioqsrsc4DORiFRWlngH6M4YbQHgIqm8fzPBFsiU+vrkg4pkjbZUVVmjMQCADoQVIFOam1M7PzrIWVNjjcoAACQRVoDMKSlJ/XuMkRobrVEZAIAkwgqQORUV1jyUrjs/JyPVURkAyGOEFSBTvF5rwqyUemDpy6gMAOQpwgqQScGgtGWLNHZscud7PFIgYI3KAAAkEVaAzAsGpSNHpO3bpY0brd4qHk/30Zbo/bo6+q0AQCc0hQOyweuVKis/uz9xYvyutnV19FkBgC4IK4AdgkFpzhz2CwKAJBBWALt0HW0BAMRFWAHchh2gAeQYwgrgJuwADSAHsRoIcIvoDtBd9ytiTyIADkdYAdwgErFGVOJtss6eRAAcjrACuEFvO0DH25MoEpF27JA2bbK+EmQA2IQ5K4AbJLvXUPQ85rYAcBDCCuAGye41VFLy2dyWrpeMmpqkW2+1OvBecQUriQBkjceYeBexc0c4HJbP51NbW5uKiorsLgdwpkhEKiuzAke8P3mPxxo5+c1vpMsuS3zJqDNGWwD0USrv37bOWSkrK5PH44m5Pfroo3aWBOSnRDtAd96TaOfO5IOKxEoiAFlh+wTbp556Ss3NzR23xx9/3O6SgPzU0w7Qfr91PBhMfm5LFCuJAGSB7XNWhg8frjFjxthdBuAOve1JlOzcls46ryRi+wAAGWDrnJWysjK1t7fr7NmzCgQCuu222/TVr35VgwcP7vF72tvb1d7e3nE/HA4rEAgwZwVIh97mtiSycaM0b17in02bfwCfypk5K9XV1XrllVe0fft2LVq0SHV1dfqbv/mbhN9TW1srn8/XcQsEAlmqFnCBRHNbepNoVCYUskLQzJnS/PnW17Iy5roASEraR1aWLVum5cuXJzxnz549mjp1arfjW7duVVVVlU6cOKERI0bE/V5GVoAsiNdnpSfRlUSHD8cfKelpKXQ0DEXnywBwlVRGVtIeVk6cOKETJ04kPKesrEyFhYXdjjc1Ncnv92vXrl2aNm1aUr+PpctAhnS+bPPee9KyZdbxzi8ZvQWO6GWlnkJPb0EHQN5K5f077RNsR44cqZEjR/bpe/ft2ydJKunLJD8A6eX1xk6YnTgxflfburqeR0ZSafPP5FwAPbBtNdBPf/pT7dq1SzNnzpTP59OePXv04IMP6k//9E81btw4u8oC0JPeVhLFk2qbfwCIw7awUlBQoM2bN2v58uVqb2/X+PHjde+99+qRRx6xqyQAvek62tKbVNr8A0APaLcPIHOSbfPPnBXAdXJm6TKAPJdsm3+CCoAECCsAMiuZNv95JhKRduyQNm2yvrITAdA/trfbB+ACfZmcm6Pitahhc2qgf5izAgBpQv87IHnMWQGALItErBGVeB//2Jwa6B/CCgCkQSr97wCkhrACAGlA/zsgcwgrAJAG9L8DMoewAgBpUFFhrfrp2k4myuORAgHrPACpIawAQBrQ/w7IHMIKAKSJC/vfAVlBUzgASFYk0mtjOxf1vwOyhrACAMlIoTVtqptTA0iMy0AA0Jtoa9qujVSamqzjoZA9dQEuQVgBgET60pqWnQyBtCKsAEAiqbamDYWksjJp5kxp/nzra1kZoy9APxBWACCRVFrTcrkIyAjCCuAyXKFIUbItZ0ePZidDIEMIK4CLcIWiD5JtTSuxkyGQIYQVwCW4QtFHybambW1N7uexkyGQMsIK4AJ9WdCCTpJpTctOhkDGeIyJ9/KVO8LhsHw+n9ra2lRUVGR3OYAj7dhhXfLpzfbtNDNLKFEH20jEuqbW1BQ/FXo8Vrg5fJh2toBSe/+mgy3gAqksaEECiVrTRi8XVVVZwaRzYGEnQ6BfuAwEuABXKLKEnQyBjOAyEOACXKHIsiQ2PATcjstAAGJwhSLL2MkQSCsuAwEuwRWK/qOhHmAPRlYAFwkGpTlzuELRF6GQtfy7c58av98asSLoAZnFnBUA6EW0oV7XV8voJTRGpoDUpfL+zWUgAEiAhnqA/QgrAJBAfT1b/gB2I6wAQAI01APsR1gBgARoqAfYj7ACAAlUVFirfrpuuBzl8UiBgHUegMwgrABAAtGGelL3wEJDPSA7CCsA0Asa6nVCZzzYgKZwAJAEGuqJzniwDU3hAAC9ozMe0oymcACA9KEzHmxGWAEAJEZnPNiMsAIASIzOeLAZE2wBAImlqzNeJOLyGcroK0ZWAACJpaMzXigklZVJM2dK8+dbX8vKrONALwgrAIDE+tsZL7qSqOu8l6Ym6dZbpQcfpGcLEiKsAAB619fOeMmsJKqrY6QFCdFnBQCQvFTnnezYYQWRZNCzxVVSef92zQTbSCSic+fO2V0G+mjQoEHyMhEPsJ/XK1VWJn9+KiuEjLECS02N1S6Yv3l8Ku/DijFGLS0t+r//+z+7S0E/XXzxxRozZow8PU3yA+A8ya4kiurcsyWVUIS8lvdhJRpURo8eraFDh/JGl4OMMfrtb3+r1tZWSVJJqi9+AOwTXUnU1BR/3kpP6NmCTvI6rEQikY6gMmLECLvLQT8MGTJEktTa2qrRo0dzSQjIFdGVRFVV1iWeZAMLH0rQSV6vBorOURk6dKjNlSAdos8jc4+yIxKx5kZu2sSqUvRTTyuJ4kmmZwtcJ6/DShSXfvIDz2P20L8LaRcMSkeOSNu3WxNo40mmZwtcyRVhBUDyEvXvqqoisKAfoiuJ/vEfpa1brbksnfXWswWulddzVgCkprf+XawqRdoEg9b/SOwVhCQwsuIwHo8n4W3hwoV2l4g8Vl/ffUSls86rSoF+i460zJtnfSWooAeMrCQhmxuFNndarrd582Y98cQT+vWvf91xLLoqJurcuXMaNGhQZoqB6yS7WpRVpQCyiZGVXmR7ouGYMWM6bj6fTx6Pp+P+mTNndPHFF+tf//VfVVlZqcLCQn33u9/VsmXLdN1118X8nLq6OpWVlcUcW79+vSZMmKDCwkJdeeWVWrVqVWb+I5Czkl0tyqpSANlEWEnAqRMNlyxZogceeEAHDhzQTTfdlNT3rFu3TkuXLtWKFSt04MABPfPMM/ra176mb3/72xmuFrkk2r+rp4VXrCoFYAcuA/XAyRMNa2pqFExxtvzXv/51Pf/88x3fV15erv3792vNmjVasGBBJspEDkrUv4tVpXCdbM4BQEKMrPTAyRMNp06dmtL5x48fV2Njo+6++25ddNFFHbenn35a77//foaqRK7qqX8Xq0rhKjQbchRGVnrg5ImGw4YNi7k/YMAAmS5DQJ27vF64cEGSdSlo2rRpMefRth7xsKoUrhadA9B1aD06B4DUnnWElR7k0kTDUaNGqaWlRcaYji6vDQ0NHY8XFxdr7NixOnTokO68806bqkSuia4qBVzFyXMAXIyw0oPeNgr1eKzHnTDRsLKyUsePH9dzzz2nqqoq/ehHP9IPf/hDFRUVdZyzbNkyPfDAAyoqKtLNN9+s9vZ2/fznP9fHH3+sxYsX21g9ADhIKnMASPNZw5yVHkQnGkrdV0Y4baLhhAkTtGrVKr300ku69tprtXv3bj388MMx59xzzz365je/qQ0bNuiaa67RjTfeqA0bNqi8vNymqgHAgZw8B8DFPKbrZIccEw6H5fP51NbWFjOSIElnzpzR4cOHVV5ersLCwj79/FDIGhHsHLQDASuocMkyu9LxfAJAQjt2WJNpe7N9OyMr/ZTo/bsrLgP1gomGwGdYyYm8l0tzAFyEsJIEJhoC8UcZ/X7rcimjjMgbNBtyJOasAOiVU7s5AxlBsyHHYWQFQEKs5IQr2TkHgOut3WR0ZGXFihWaMWOGhg4dqosvvjjuOUePHtXs2bM1bNgwjRw5Ug888IDOnj2bybIApMDJ3ZyBjIrOAZg3z/qajcBA59y4MhpWzp49q9tuu01//dd/HffxSCSiW265RadPn9bbb7+tV155RVu3btVDDz2UybIApCBdKzkjEWuhxaZN1tdIpL+VAXmG6609yuhloOXLl0uSNmzYEPfx119/Xfv371djY6NKS0slSc8//7wWLlyoFStW9LqUCUDmpaObM5NzgV5wvTUhWyfY/vSnP9XEiRM7gook3XTTTWpvb9fevXvjfk97e7vC4XDMDUDmRFdydm2OGOXxWL2HelrJyYdFIAlcb03I1rDS0tKi4uLimGOf+9znNHjwYLW0tMT9ntraWvl8vo5bIBDIRqmAa/Wnm3NvHxYl68Mil4TgenTOTSjlsLJs2TJ5PJ6Et5///OdJ/zxPnI9rnTfk6+qxxx5TW1tbx62xsTHV/wR0smzZMl133XUd9xcuXKi5c+dmvY4jR47I4/HEbMAI5+jrSk4+LAJJyqXdc22Q8pyVRYsW6Y477kh4TllZWVI/a8yYMfrZz34Wc+zjjz/WuXPnuo24RBUUFKigoCCpn5/LFi5cqG9/+9uSpIEDByoQCCgYDGr58uUaNmxYxn7vypUrlewODEeOHFF5ebn27dsXE3iQn/qykpMPi0CS6JybUMphZeTIkRo5cmRafvn06dO1YsUKNTc3q+TTtPj666+roKBAU6ZMScvvSAub1rz/0R/9kdavX69z586pvr5e99xzj06fPq3Vq1fHnHfu3DkNGjQoLb/T5/Ol5ecgP6XazZkPi0CS6JybUEbnrBw9elQNDQ06evSoIpGIGhoa1NDQoFOnTkmSZs2apauuukp33XWX9u3bpzfeeEMPP/yw7r33XuesBLJxzXtBQYHGjBmjQCCg+fPn684779T3v//9jks3L7/8si699FIVFBTIGKO2tjb95V/+pUaPHq2ioiL9wR/8gd55552Yn/l3f/d3Ki4u1vDhw3X33XfrzJkzMY93vQx04cIFPfvss7r88stVUFCgcePGacWKFZLUsWPzpEmT5PF4VNnpXWz9+vWaMGGCCgsLdeWVV2rVqlUxv2f37t2aNGmSCgsLNXXqVO3bty+N/3Jwiv5OzgVcxe7OuU7uL2AyaMGCBUZSt9v27ds7zvnggw/MLbfcYoYMGWIuueQSs2jRInPmzJmkf0dbW5uRZNra2ro99sknn5j9+/ebTz75pG//AVu3GuPxGGNl3M9uHo9127q1bz83CQsWLDBz5syJOfaVr3zFjBgxwjz55JNm2LBh5qabbjK/+MUvzDvvvGMuXLhgrr/+ejN79myzZ88ec/DgQfPQQw+ZESNGmI8++sgYY8zmzZvN4MGDzbp168z//M//mKVLl5rhw4eba6+9tsff+8gjj5jPfe5zZsOGDeY3v/mNqa+vN+vWrTPGGLN7924jyfzkJz8xzc3NHb9n7dq1pqSkxGzdutUcOnTIbN261VxyySVmw4YNxhhjTp06ZUaNGmVuv/1286tf/cq8+uqr5tJLLzWSzL59+3r8N+n38wlbRP+Muv4pZeHPCMhN588bs327MRs3Wl/Pn8/879y61Ri/P/aP1O835t/+LWO1JHr/7iqjYSUbMhZWzp/v/sR1faUNBDL2P1HX0PCzn/3MjBgxwnzpS18yTz75pBk0aJBpbW3tePyNN94wRUVF3YLeZZddZtasWWOMMWb69Onmvvvui3l82rRpPYaVcDhsCgoKOsJJV4cPH44bMAKBgNm4cWPMsa9//etm+vTpxhhj1qxZYy655BJz+vTpjsdXr15NWMlj8V4HAwGCCuAIPX0wj3fz+9P2h5tKWGEjw544YBnDf/zHf+iiiy5SYWGhpk+frhtuuEHf+MY3JEnjx4/XqFGjOs7du3evTp06pREjRuiiiy7quB0+fFjvv/++JOnAgQOaPn16zO/oer+zAwcOqL29XV/4wheSrvn48eNqbGzU3XffHVPH008/HVPHtddeq6FDhyZVB3JfMCgdOSJt3y5t3Gh9PXyYhnCA7RL1F4jHpgZJbGTYEwcsY5g5c6ZWr16tQYMGqbS0NGYSbdcVQRcuXFBJSYl27NjR7ef0tC9Tb4YMGZLy91y4cEGStG7dOk2bNi3mMe+nE8NMsn8UyCupTs4FkAW9fTDvyqZuuoys9MQByxiGDRumyy+/XOPHj+91tc/kyZPV0tKigQMH6vLLL4+5RVdvTZgwQbt27Yr5vq73O7viiis0ZMgQvfHGG3EfHzx4sCRrj6eo4uJijR07VocOHepWR3RC7lVXXaV33nlHn3zySVJ1AAAypC8fuG1okERY6UmOLWP44he/qOnTp2vu3Ln68Y9/rCNHjmjnzp16/PHHO5r0VVdX6+WXX9bLL7+sgwcP6sknn9S7777b488sLCzUkiVL9Mgjj+g73/mO3n//fe3atUvf+ta3JEmjR4/WkCFD9KMf/Uj/+7//q7a2NklWo7na2lqtXLlSBw8e1C9/+UutX79eL7zwgiRp/vz5GjBggO6++27t379fr732mv7hH/4hw/9CAIBu+vOBO4sNkggrPelPj3EbeDwevfbaa7rhhhv05S9/Wb/zO7+jO+64Q0eOHOlosHf77bfriSee0JIlSzRlyhR98MEHPe6IHfW1r31NDz30kJ544glNmDBBt99+u1pbWyVZzer+6Z/+SWvWrFFpaanmzJkjSbrnnnv0zW9+Uxs2bNA111yjG2+8URs2bOgYWbnooov06quvav/+/Zo0aZKWLl2qZ599NoP/OgCAuHr7YJ5IFhskeUyOTyAIh8Py+Xxqa2vr1pvlzJkzOnz4sMrLy1VYWNi3XxBvu9hAwAoqzA7MqrQ8nwCAWNHdRqXkJtpGu+kePtyvD+yJ3r+7YoJtb/rSYxwAgFwRbUbX9YN5PDZdWSCsJINlDACAfBbvg/nx49LixbEBxu+35coCYQUAAMT/YB4MOuLKAmEFAADE55ArC6wGAgAAjuaKsBLtqorcxvMIAO6U15eBBg8erAEDBujYsWMaNWqUBg8eLE9f1pLDVsYYnT17VsePH9eAAQM6OucCANwhr8PKgAEDVF5erubmZh07dszuctBPQ4cO1bhx4zRggCsGBAEAn8rrsCJZoyvjxo3T+fPnY/awQW7xer0aOHAgI2MA4EJ5H1YkqxX9oEGDet0MEAAAOA/j6QAAwNEIKwAAwNEIKwAAwNFyfs5KdNPocDhscyUAACBZ0fdtk8ROzzkfVk6ePClJCgQCNlcCAABSdfLkSfl8voTneEwykcbBLly4oGPHjmn48OH9WtYaDocVCATU2NiooqKiNFaIVPA8OAPPgzPwPDgDz0NmGGN08uRJlZaW9to/K+dHVgYMGCC/35+2n1dUVMT/jA7A8+AMPA/OwPPgDDwP6dfbiEoUE2wBAICjEVYAAICjEVY+VVBQoCeffFIFBQV2l+JqPA/OwPPgDDwPzsDzYL+cn2ALAADyGyMrAADA0QgrAADA0QgrAADA0QgrAADA0QgrklatWqXy8nIVFhZqypQpqq+vt7skV6mtrdXv/d7vafjw4Ro9erTmzp2rX//613aX5Xq1tbXyeDyqqamxuxRXampq0p//+Z9rxIgRGjp0qK677jrt3bvX7rJc5fz583r88cdVXl6uIUOG6NJLL9VTTz2lCxcu2F2a67g+rGzevFk1NTVaunSp9u3bp4qKCt188806evSo3aW5xptvvqn7779fu3bt0rZt23T+/HnNmjVLp0+ftrs019qzZ4/Wrl2r3/3d37W7FFf6+OOPdf3112vQoEH64Q9/qP379+v555/XxRdfbHdprvLss8/qn//5n/Xiiy/qwIEDeu655/T3f//3+sY3vmF3aa7j+qXL06ZN0+TJk7V69eqOYxMmTNDcuXNVW1trY2Xudfz4cY0ePVpvvvmmbrjhBrvLcZ1Tp05p8uTJWrVqlZ5++mldd911qqurs7ssV3n00Uf1X//1X4zy2uxP/uRPVFxcrG9961sdx2699VYNHTpU//Iv/2JjZe7j6pGVs2fPau/evZo1a1bM8VmzZmnnzp02VYW2tjZJ0iWXXGJzJe50//3365ZbbtEXv/hFu0txrR/84AeaOnWqbrvtNo0ePVqTJk3SunXr7C7LdT7/+c/rjTfe0MGDByVJ77zzjt5++2398R//sc2VuU/Ob2TYHydOnFAkElFxcXHM8eLiYrW0tNhUlbsZY7R48WJ9/vOf18SJE+0ux3VeeeUV/eIXv9CePXvsLsXVDh06pNWrV2vx4sX627/9W+3evVsPPPCACgoK9Bd/8Rd2l+caS5YsUVtbm6688kp5vV5FIhGtWLFC8+bNs7s013F1WInyeDwx940x3Y4hOxYtWqT//u//1ttvv213Ka7T2Nio6upqvf766yosLLS7HFe7cOGCpk6dqmeeeUaSNGnSJL377rtavXo1YSWLNm/erO9+97vauHGjrr76ajU0NKimpkalpaVasGCB3eW5iqvDysiRI+X1eruNorS2tnYbbUHmfeUrX9EPfvADvfXWW/L7/XaX4zp79+5Va2urpkyZ0nEsEonorbfe0osvvqj29nZ5vV4bK3SPkpISXXXVVTHHJkyYoK1bt9pUkTt99atf1aOPPqo77rhDknTNNdfogw8+UG1tLWEly1w9Z2Xw4MGaMmWKtm3bFnN827ZtmjFjhk1VuY8xRosWLVIoFNJ//ud/qry83O6SXOkLX/iCfvnLX6qhoaHjNnXqVN15551qaGggqGTR9ddf3235/sGDBzV+/HibKnKn3/72txowIPZt0uv1snTZBq4eWZGkxYsX66677tLUqVM1ffp0rV27VkePHtV9991nd2mucf/992vjxo3693//dw0fPrxjpMvn82nIkCE2V+cew4cP7zZPaNiwYRoxYgTzh7LswQcf1IwZM/TMM8/oS1/6knbv3q21a9dq7dq1dpfmKrNnz9aKFSs0btw4XX311dq3b59eeOEFffnLX7a7NPcxMC+99JIZP368GTx4sJk8ebJ588037S7JVSTFva1fv97u0lzvxhtvNNXV1XaX4UqvvvqqmThxoikoKDBXXnmlWbt2rd0luU44HDbV1dVm3LhxprCw0Fx66aVm6dKlpr293e7SXMf1fVYAAICzuXrOCgAAcD7CCgAAcDTCCgAAcDTCCgAAcDTCCgAAcDTCCgAAcDTCCgAAcDTCCgAAcDTCCgAAcDTCCgAAcDTCCgAAcDTCCgAAcLT/ByGJ178+VlLmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.scatter(test_X.flatten(), test_Y, color=\"blue\", label=\"True\")\n",
    "plt.scatter(test_X.flatten(), test_Y_pred, color=\"red\", label=\"Predicted\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
